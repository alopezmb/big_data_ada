version: '3'
services:

  mongodb:
    container_name: mongodb
    build: ./mongodb
    ports:
      - "27017:27017" # remember the port expose syntax is HOST:CONTAINER !
    volumes:
      - mongodbdata:/data/mongodb
    networks:
      - flight_prediction_network

  webserver:
    container_name: webserver
    build: ./flask
    ports:
      - "1212:80"
    networks:
      - flight_prediction_network
  
  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:5.3.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - flight_prediction_network

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:5.3.0
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
     - zookeeper
    networks:
      - flight_prediction_network

  # Container that will create topics and then will die gracefully.
  kafka-setup:
    image: confluentinc/cp-kafka:5.3.0
    hostname: kafka-setup
    container_name: kafka-setup
    depends_on:
      - kafka
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:9092 1 20 && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper:2181 --partitions 1 --replication-factor 1 --topic flight_delay_classification_request'"
    networks:
      - flight_prediction_network
 
  #testkafka:
  #  container_name: testkafka
  #  build: ./testkafka
  #  networks:
  #    - flight_prediction_network

  spark-master:
    container_name: spark-master
    image: bitnami/spark:2.4.4
    environment:
      - SPARK_MODE=master
    ports:
      - '8080:8080'
    volumes:
      - ./spark/models/:/job_data/models #Bind mount to mount models dir on each spark node
    networks:
      - flight_prediction_network

  spark-worker-1:
    container_name: spark-worker-1
    image: bitnami/spark:2.4.4
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    ports:
    - '8081:8081'
    volumes:
      - ./spark/models/:/job_data/models  #Bind mount to mount models dir on each spark node
    networks:
      - flight_prediction_network


networks:
  flight_prediction_network:
    driver: bridge

volumes:
  mongodbdata:
